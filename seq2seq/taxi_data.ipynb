{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     value\n",
      "timestamp                 \n",
      "2014-07-01 00:00:00  10844\n",
      "2014-07-01 00:30:00   8127\n",
      "2014-07-01 01:00:00   6210\n",
      "2014-07-01 01:30:00   4656\n",
      "2014-07-01 02:00:00   3820\n",
      "                     value\n",
      "timestamp                 \n",
      "2015-01-31 21:30:00  24670\n",
      "2015-01-31 22:00:00  25721\n",
      "2015-01-31 22:30:00  27309\n",
      "2015-01-31 23:00:00  26591\n",
      "2015-01-31 23:30:00  26288\n",
      "datetime64[ns] 10320\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('../data/nyc_taxi.csv')\n",
    "data['timestamp'] = pd.to_datetime(data['timestamp'])\n",
    "data.set_index('timestamp',inplace=True)\n",
    "print data.head()\n",
    "print data.tail()\n",
    "print data.index.dtype,len(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(215, 48)\n",
      "(211, 4, 48) (211, 1, 48)\n",
      "(201, 4, 48) (201, 1, 48) (10, 4, 48) (10, 1, 48)\n",
      "[[-0.61874487 -1.01029084 -1.28654908 -1.51049551 -1.63097119 -1.76744305\n",
      "  -1.84007432 -1.88402777 -1.86140256 -1.87048146 -1.81903431 -1.55257553\n",
      "  -1.24101042 -0.59064348 -0.18454243  0.10482979  0.40097516  0.75058522\n",
      "   0.63428872  0.71614301  0.55430785  0.37215323  0.30427757  0.47922671\n",
      "   0.54335551  0.5401851   0.43815545  0.62275994  0.63529748  0.78589209\n",
      "   0.61137528  0.49089959  0.1571416  -0.01795165  0.29764853  0.63227118\n",
      "   1.12815256  1.79566855  1.68455999  1.4074371   1.11503858  0.75750248\n",
      "   1.19084026  1.3404261   1.17887916  0.95046533  0.71571068  0.14028077]\n",
      " [-0.25472384 -0.74829946 -1.09041582 -1.32877321 -1.48686152 -1.65777559\n",
      "  -1.75014989 -1.81615212 -1.81110828 -1.8233576  -1.7681636  -1.53557059\n",
      "  -1.20325369 -0.5850232  -0.20298847  0.22516136  0.57909471  0.69395012\n",
      "   0.62895666  0.55574895  0.31321237  0.3986694   0.28756085  0.49738453\n",
      "   0.5759243   0.59393801  0.50862508  0.56785416  0.49118781  0.49796097\n",
      "   0.40774831  0.21420903 -0.07256922 -0.18007503  0.33036142  0.97726973\n",
      "   1.22427371  1.35094611  1.40498723  1.69104493  0.9902396   0.44982834\n",
      "   0.82235184  1.07194978  1.04673059  0.56468374  0.34304307  0.02441659]\n",
      " [-0.35905924 -0.65938379 -0.96864315 -1.15857969 -1.34188719 -1.54983745\n",
      "  -1.71023151 -1.75663482 -1.72810111 -1.73804468 -1.74914112 -1.51971853\n",
      "  -1.24677481 -0.72408904 -0.41756777 -0.0812158   0.23640192  0.54364373\n",
      "   0.46294232  0.29981017  0.13826323  0.18322545  0.10886486  0.23640192\n",
      "   0.3554365   0.50833686  0.56309854  0.59422623  0.60892541  0.56785416\n",
      "   0.4403171   0.21579423 -0.0753073  -0.19866518  0.26954714  0.64235886\n",
      "   0.89210092  1.08419911  2.13965833  0.91703189  1.08751363  1.01603523\n",
      "   1.08448733  0.63918844  0.28799318  0.21161505  0.1482068   0.12716679]\n",
      " [ 0.06534374 -0.10701143 -0.37505542 -0.54712236 -0.74325562 -0.97037246\n",
      "  -1.14388051 -1.23351672 -1.36624173 -1.53672347 -1.68299478 -1.70936685\n",
      "  -1.66339587 -1.57044513 -1.48570864 -1.4715859  -1.43714369 -1.34909268\n",
      "  -1.12399337 -1.05179443 -0.93881245 -0.77913893 -0.59280513 -0.27475508\n",
      "  -0.21970519 -0.20183559  0.06289387 -0.13136596  0.48167657  0.450693\n",
      "   0.20714765  0.18437832 -0.06262565 -0.24045698 -0.43702257 -0.49884562\n",
      "   0.05035633 -0.00872863 -0.01996919 -0.09375334 -0.10412924 -0.19333312\n",
      "  -0.1587468  -0.16090845  0.06563196  0.20916519  0.41019818  0.41754777]]\n",
      "[[ 0.35140143  0.15152132 -0.10038238 -0.37505542 -0.5953991  -0.86272254\n",
      "  -1.02715167 -1.15886791 -1.25815948 -1.54436128 -1.7309833  -1.81917842\n",
      "  -1.81399047 -1.72781289 -1.65431696 -1.55531362 -1.50674866 -1.28107291\n",
      "  -1.10727665 -0.883042   -0.70002272 -0.52593824 -0.51051851 -0.29392167\n",
      "  -0.36237376 -0.30357702 -0.27014358 -0.25775014 -0.18958627 -0.20486189\n",
      "  -0.17560763 -0.13468049 -0.28224879 -0.20601477 -0.17877804 -0.05729359\n",
      "  -0.08107169  0.13653391  0.43873189  0.24836302 -0.14375939 -0.09519444\n",
      "   0.02239906  0.04603304  0.13120186  0.33713458  0.18063147  0.26925892]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# use 4 days to predict 1 day\n",
    "import numpy as np\n",
    "\n",
    "ONE_DAY_DATA_LEN = 48\n",
    "def make_data(X, pre_days=4):\n",
    "    xs = []\n",
    "    ys = []\n",
    "    data_len = len(X)\n",
    "    for i in range(data_len-pre_days):\n",
    "        x = X[i:i+pre_days]\n",
    "        y = X[i+pre_days:i+pre_days+1]\n",
    "\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "daily_data = data.values.flatten()\n",
    "\n",
    "# preprocess data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "daily_data = scaler.fit_transform(daily_data).reshape(-1,ONE_DAY_DATA_LEN)\n",
    "\n",
    "print daily_data.shape\n",
    "x,y = make_data(daily_data)\n",
    "print x.shape,y.shape\n",
    "\n",
    "def split_train_test(x, y, n):\n",
    "    x_train, x_test = x[0:-n], x[-n:]\n",
    "    y_train, y_test = y[0:-n], y[-n:]\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "X_train, Y_train, X_test, Y_test = split_train_test(x, y, 10)\n",
    "print X_train.shape, Y_train.shape, X_test.shape, Y_test.shape\n",
    "_,input_len,input_dim = X_train.shape\n",
    "_,output_len,output_dim = Y_train.shape\n",
    "hidden_dim = output_len * 2\n",
    "\n",
    "print X_train[0]\n",
    "print Y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n",
      "compile done\n"
     ]
    }
   ],
   "source": [
    "# get errors\n",
    "\n",
    "import keras\n",
    "from seq2seq.models import SimpleSeq2seq, Seq2seq\n",
    "\n",
    "\n",
    "X_train = X_train.astype(\"float32\")\n",
    "Y_train = Y_train.astype(\"float32\")\n",
    "\n",
    "model = Seq2seq(batch_input_shape=(1,input_len,input_dim),output_dim=output_dim,hidden_dim=hidden_dim,output_length=output_len)\n",
    "model.compile(loss='mse', optimizer='rmsprop')\n",
    "print 'compile done'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 201 samples, validate on 10 samples\n",
      "Epoch 1/1\n",
      "201/201 [==============================] - 10s - loss: 0.8291 - val_loss: 1.0435\n",
      "Train on 201 samples, validate on 10 samples\n",
      "Epoch 1/1\n",
      "201/201 [==============================] - 5s - loss: 0.6220 - val_loss: 0.8911\n",
      "Train on 201 samples, validate on 10 samples\n",
      "Epoch 1/1\n",
      "201/201 [==============================] - 7s - loss: 0.4398 - val_loss: 0.8299\n",
      "Train on 201 samples, validate on 10 samples\n",
      "Epoch 1/1\n",
      "201/201 [==============================] - 10s - loss: 0.3489 - val_loss: 0.7708\n",
      "Train on 201 samples, validate on 10 samples\n",
      "Epoch 1/1\n",
      "201/201 [==============================] - 13s - loss: 0.3350 - val_loss: 0.7605\n",
      "Train on 201 samples, validate on 10 samples\n",
      "Epoch 1/1\n",
      "201/201 [==============================] - 13s - loss: 0.3351 - val_loss: 0.7561\n",
      "Train on 201 samples, validate on 10 samples\n",
      "Epoch 1/1\n",
      "201/201 [==============================] - 11s - loss: 0.3254 - val_loss: 0.7514\n",
      "Train on 201 samples, validate on 10 samples\n",
      "Epoch 1/1\n",
      "201/201 [==============================] - 11s - loss: 0.3274 - val_loss: 0.7529\n",
      "Train on 201 samples, validate on 10 samples\n",
      "Epoch 1/1\n",
      "201/201 [==============================] - 11s - loss: 0.3222 - val_loss: 0.7519\n",
      "Train on 201 samples, validate on 10 samples\n",
      "Epoch 1/1\n",
      "201/201 [==============================] - 12s - loss: 0.3194 - val_loss: 0.7585\n",
      "Train on 201 samples, validate on 10 samples\n",
      "Epoch 1/1\n",
      "201/201 [==============================] - 13s - loss: 0.3119 - val_loss: 0.7558\n",
      "Train on 201 samples, validate on 10 samples\n",
      "Epoch 1/1\n",
      "201/201 [==============================] - 10s - loss: 0.3101 - val_loss: 0.7520\n",
      "Train on 201 samples, validate on 10 samples\n",
      "Epoch 1/1\n",
      "201/201 [==============================] - 10s - loss: 0.3020 - val_loss: 0.7516\n",
      "Train on 201 samples, validate on 10 samples\n",
      "Epoch 1/1\n",
      "201/201 [==============================] - 9s - loss: 0.2984 - val_loss: 0.7520\n",
      "Train on 201 samples, validate on 10 samples\n",
      "Epoch 1/1\n",
      "201/201 [==============================] - 8s - loss: 0.2937 - val_loss: 0.7505\n",
      "Train on 201 samples, validate on 10 samples\n",
      "Epoch 1/1\n",
      "201/201 [==============================] - 8s - loss: 0.2903 - val_loss: 0.7461\n",
      "Train on 201 samples, validate on 10 samples\n",
      "Epoch 1/1\n",
      "201/201 [==============================] - 9s - loss: 0.2819 - val_loss: 0.7503\n",
      "Train on 201 samples, validate on 10 samples\n",
      "Epoch 1/1\n",
      "201/201 [==============================] - 11s - loss: 0.2701 - val_loss: 0.7483\n",
      "Train on 201 samples, validate on 10 samples\n",
      "Epoch 1/1\n",
      "201/201 [==============================] - 10s - loss: 0.2665 - val_loss: 0.7526\n",
      "Train on 201 samples, validate on 10 samples\n",
      "Epoch 1/1\n",
      "201/201 [==============================] - 9s - loss: 0.2531 - val_loss: 0.7544\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    model.fit(X_train,Y_train,nb_epoch=1,batch_size=1,shuffle=False,verbose=1,validation_data=(X_test, Y_test))\n",
    "    model.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 1, 1, 48)\n",
      "0.449149784739\n",
      "0.417516984421\n",
      "4295.83871001 13846.8083333 7897.20557781\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "pred = []\n",
    "for x in X_test:\n",
    "    pred.append(model.predict(np.array([x])))\n",
    "pred = np.array(pred)\n",
    "print pred.shape\n",
    "pred = scaler.inverse_transform(pred.reshape(-1,1))\n",
    "truth = scaler.inverse_transform(Y_test.reshape(-1,1))\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "print metrics.explained_variance_score(truth,pred)\n",
    "print metrics.r2_score(truth,pred)\n",
    "print metrics.mean_absolute_error(truth,pred),truth.mean(),truth.std()\n",
    "\n",
    "plt.plot(pred,label='pred')\n",
    "plt.plot(truth,label='truth')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
