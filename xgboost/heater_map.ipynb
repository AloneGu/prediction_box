{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0]\n",
      "(168, 96)\n",
      "(168, 24)\n",
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      " [1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 1]\n",
      " [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0 1 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('../data/C89346C23293_map.csv')\n",
    "\n",
    "data = df.values[:,1:]\n",
    "print data[0]\n",
    "print data.shape\n",
    "data = data.flatten().reshape(-1,4)\n",
    "data = map(int,np.sum(data,axis=1).clip(max=1))\n",
    "data = np.array(data).reshape(-1,24)\n",
    "print data.shape\n",
    "print data[:30]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168\n",
      "(164, 96) (164, 24)\n",
      "(134, 96) (134, 24) (30, 96) (30, 24)\n",
      "compile done\n",
      "Train on 134 samples, validate on 30 samples\n",
      "Epoch 1/100\n",
      "134/134 [==============================] - 0s - loss: 1.4187 - val_loss: 0.2981\n",
      "Epoch 2/100\n",
      "134/134 [==============================] - 0s - loss: 1.2457 - val_loss: 0.2458\n",
      "Epoch 3/100\n",
      "134/134 [==============================] - 0s - loss: 1.1491 - val_loss: 0.2150\n",
      "Epoch 4/100\n",
      "134/134 [==============================] - 0s - loss: 1.0756 - val_loss: 0.1915\n",
      "Epoch 5/100\n",
      "134/134 [==============================] - 0s - loss: 1.0128 - val_loss: 0.1726\n",
      "Epoch 6/100\n",
      "134/134 [==============================] - 0s - loss: 0.9567 - val_loss: 0.1571\n",
      "Epoch 7/100\n",
      "134/134 [==============================] - 0s - loss: 0.9051 - val_loss: 0.1433\n",
      "Epoch 8/100\n",
      "134/134 [==============================] - 0s - loss: 0.8584 - val_loss: 0.1312\n",
      "Epoch 9/100\n",
      "134/134 [==============================] - 0s - loss: 0.8143 - val_loss: 0.1205\n",
      "Epoch 10/100\n",
      "134/134 [==============================] - 0s - loss: 0.7718 - val_loss: 0.1105\n",
      "Epoch 11/100\n",
      "134/134 [==============================] - 0s - loss: 0.7331 - val_loss: 0.1021\n",
      "Epoch 12/100\n",
      "134/134 [==============================] - 0s - loss: 0.6962 - val_loss: 0.0945\n",
      "Epoch 13/100\n",
      "134/134 [==============================] - 0s - loss: 0.6603 - val_loss: 0.0872\n",
      "Epoch 14/100\n",
      "134/134 [==============================] - 0s - loss: 0.6271 - val_loss: 0.0810\n",
      "Epoch 15/100\n",
      "134/134 [==============================] - 0s - loss: 0.5953 - val_loss: 0.0751\n",
      "Epoch 16/100\n",
      "134/134 [==============================] - 0s - loss: 0.5658 - val_loss: 0.0704\n",
      "Epoch 17/100\n",
      "134/134 [==============================] - 0s - loss: 0.5379 - val_loss: 0.0669\n",
      "Epoch 18/100\n",
      "134/134 [==============================] - 0s - loss: 0.5116 - val_loss: 0.0636\n",
      "Epoch 19/100\n",
      "134/134 [==============================] - 0s - loss: 0.4868 - val_loss: 0.0606\n",
      "Epoch 20/100\n",
      "134/134 [==============================] - 0s - loss: 0.4630 - val_loss: 0.0582\n",
      "Epoch 21/100\n",
      "134/134 [==============================] - 0s - loss: 0.4410 - val_loss: 0.0562\n",
      "Epoch 22/100\n",
      "134/134 [==============================] - 0s - loss: 0.4200 - val_loss: 0.0544\n",
      "Epoch 23/100\n",
      "134/134 [==============================] - 0s - loss: 0.4004 - val_loss: 0.0531\n",
      "Epoch 24/100\n",
      "134/134 [==============================] - 0s - loss: 0.3816 - val_loss: 0.0528\n",
      "Epoch 25/100\n",
      "134/134 [==============================] - 0s - loss: 0.3642 - val_loss: 0.0528\n",
      "Epoch 26/100\n",
      "134/134 [==============================] - 0s - loss: 0.3474 - val_loss: 0.0524\n",
      "Epoch 27/100\n",
      "134/134 [==============================] - 0s - loss: 0.3318 - val_loss: 0.0520\n",
      "Epoch 28/100\n",
      "134/134 [==============================] - 0s - loss: 0.3167 - val_loss: 0.0515\n",
      "Epoch 29/100\n",
      "134/134 [==============================] - 0s - loss: 0.3025 - val_loss: 0.0519\n",
      "Epoch 30/100\n",
      "134/134 [==============================] - 0s - loss: 0.2892 - val_loss: 0.0521\n",
      "Epoch 31/100\n",
      "134/134 [==============================] - 0s - loss: 0.2762 - val_loss: 0.0520\n",
      "Epoch 32/100\n",
      "134/134 [==============================] - 0s - loss: 0.2640 - val_loss: 0.0519\n",
      "Epoch 33/100\n",
      "134/134 [==============================] - 0s - loss: 0.2525 - val_loss: 0.0519\n",
      "Epoch 34/100\n",
      "134/134 [==============================] - 0s - loss: 0.2415 - val_loss: 0.0528\n",
      "Epoch 35/100\n",
      "134/134 [==============================] - 0s - loss: 0.2308 - val_loss: 0.0527\n",
      "Epoch 36/100\n",
      "134/134 [==============================] - 0s - loss: 0.2210 - val_loss: 0.0525\n",
      "Epoch 37/100\n",
      "134/134 [==============================] - 0s - loss: 0.2113 - val_loss: 0.0528\n",
      "Epoch 38/100\n",
      "134/134 [==============================] - 0s - loss: 0.2023 - val_loss: 0.0527\n",
      "Epoch 39/100\n",
      "134/134 [==============================] - 0s - loss: 0.1936 - val_loss: 0.0532\n",
      "Epoch 40/100\n",
      "134/134 [==============================] - 0s - loss: 0.1857 - val_loss: 0.0528\n",
      "Epoch 41/100\n",
      "134/134 [==============================] - 0s - loss: 0.1778 - val_loss: 0.0525\n",
      "Epoch 42/100\n",
      "134/134 [==============================] - 0s - loss: 0.1704 - val_loss: 0.0526\n",
      "Epoch 43/100\n",
      "134/134 [==============================] - 0s - loss: 0.1638 - val_loss: 0.0527\n",
      "Epoch 44/100\n",
      "134/134 [==============================] - 0s - loss: 0.1569 - val_loss: 0.0527\n",
      "Epoch 45/100\n",
      "134/134 [==============================] - 0s - loss: 0.1508 - val_loss: 0.0534\n",
      "Epoch 46/100\n",
      "134/134 [==============================] - 0s - loss: 0.1450 - val_loss: 0.0529\n",
      "Epoch 47/100\n",
      "134/134 [==============================] - 0s - loss: 0.1393 - val_loss: 0.0534\n",
      "Epoch 48/100\n",
      "134/134 [==============================] - 0s - loss: 0.1341 - val_loss: 0.0532\n",
      "Epoch 49/100\n",
      "134/134 [==============================] - 0s - loss: 0.1293 - val_loss: 0.0528\n",
      "Epoch 50/100\n",
      "134/134 [==============================] - 0s - loss: 0.1247 - val_loss: 0.0532\n",
      "Epoch 51/100\n",
      "134/134 [==============================] - 0s - loss: 0.1203 - val_loss: 0.0534\n",
      "Epoch 52/100\n",
      "134/134 [==============================] - 0s - loss: 0.1163 - val_loss: 0.0529\n",
      "Epoch 53/100\n",
      "134/134 [==============================] - 0s - loss: 0.1127 - val_loss: 0.0526\n",
      "Epoch 54/100\n",
      "134/134 [==============================] - 0s - loss: 0.1091 - val_loss: 0.0527\n",
      "Epoch 55/100\n",
      "134/134 [==============================] - 0s - loss: 0.1058 - val_loss: 0.0528\n",
      "Epoch 56/100\n",
      "134/134 [==============================] - 0s - loss: 0.1029 - val_loss: 0.0531\n",
      "Epoch 57/100\n",
      "134/134 [==============================] - 0s - loss: 0.1001 - val_loss: 0.0534\n",
      "Epoch 58/100\n",
      "134/134 [==============================] - 0s - loss: 0.0975 - val_loss: 0.0528\n",
      "Epoch 59/100\n",
      "134/134 [==============================] - 0s - loss: 0.0950 - val_loss: 0.0528\n",
      "Epoch 60/100\n",
      "134/134 [==============================] - 0s - loss: 0.0929 - val_loss: 0.0528\n",
      "Epoch 61/100\n",
      "134/134 [==============================] - 0s - loss: 0.0908 - val_loss: 0.0529\n",
      "Epoch 62/100\n",
      "134/134 [==============================] - 0s - loss: 0.0890 - val_loss: 0.0527\n",
      "Epoch 63/100\n",
      "134/134 [==============================] - 0s - loss: 0.0874 - val_loss: 0.0531\n",
      "Epoch 64/100\n",
      "134/134 [==============================] - 0s - loss: 0.0857 - val_loss: 0.0529\n",
      "Epoch 65/100\n",
      "134/134 [==============================] - 0s - loss: 0.0843 - val_loss: 0.0527\n",
      "Epoch 66/100\n",
      "134/134 [==============================] - 0s - loss: 0.0830 - val_loss: 0.0529\n",
      "Epoch 67/100\n",
      "134/134 [==============================] - 0s - loss: 0.0819 - val_loss: 0.0526\n",
      "Epoch 68/100\n",
      "134/134 [==============================] - 0s - loss: 0.0807 - val_loss: 0.0533\n",
      "Epoch 69/100\n",
      "134/134 [==============================] - 0s - loss: 0.0797 - val_loss: 0.0537\n",
      "Epoch 70/100\n",
      "134/134 [==============================] - 0s - loss: 0.0787 - val_loss: 0.0534\n",
      "Epoch 71/100\n",
      "134/134 [==============================] - 0s - loss: 0.0781 - val_loss: 0.0535\n",
      "Epoch 72/100\n",
      "134/134 [==============================] - 0s - loss: 0.0772 - val_loss: 0.0529\n",
      "Epoch 73/100\n",
      "134/134 [==============================] - 0s - loss: 0.0765 - val_loss: 0.0536\n",
      "Epoch 74/100\n",
      "134/134 [==============================] - 0s - loss: 0.0760 - val_loss: 0.0534\n",
      "Epoch 75/100\n",
      "134/134 [==============================] - 0s - loss: 0.0753 - val_loss: 0.0533\n",
      "Epoch 76/100\n",
      "134/134 [==============================] - 0s - loss: 0.0748 - val_loss: 0.0530\n",
      "Epoch 77/100\n",
      "134/134 [==============================] - 0s - loss: 0.0744 - val_loss: 0.0530\n",
      "Epoch 78/100\n",
      "134/134 [==============================] - 0s - loss: 0.0738 - val_loss: 0.0529\n",
      "Epoch 79/100\n",
      "134/134 [==============================] - 0s - loss: 0.0735 - val_loss: 0.0528\n",
      "Epoch 80/100\n",
      "134/134 [==============================] - 0s - loss: 0.0731 - val_loss: 0.0530\n",
      "Epoch 81/100\n",
      "134/134 [==============================] - 0s - loss: 0.0729 - val_loss: 0.0531\n",
      "Epoch 82/100\n",
      "134/134 [==============================] - 0s - loss: 0.0724 - val_loss: 0.0530\n",
      "Epoch 83/100\n",
      "134/134 [==============================] - 0s - loss: 0.0722 - val_loss: 0.0530\n",
      "Epoch 84/100\n",
      "134/134 [==============================] - 0s - loss: 0.0719 - val_loss: 0.0536\n",
      "Epoch 85/100\n",
      "134/134 [==============================] - 0s - loss: 0.0717 - val_loss: 0.0531\n",
      "Epoch 86/100\n",
      "134/134 [==============================] - 0s - loss: 0.0715 - val_loss: 0.0529\n",
      "Epoch 87/100\n",
      "134/134 [==============================] - 0s - loss: 0.0713 - val_loss: 0.0534\n",
      "Epoch 88/100\n",
      "134/134 [==============================] - 0s - loss: 0.0711 - val_loss: 0.0531\n",
      "Epoch 89/100\n",
      "134/134 [==============================] - 0s - loss: 0.0711 - val_loss: 0.0531\n",
      "Epoch 90/100\n",
      "134/134 [==============================] - 0s - loss: 0.0708 - val_loss: 0.0537\n",
      "Epoch 91/100\n",
      "134/134 [==============================] - 0s - loss: 0.0708 - val_loss: 0.0534\n",
      "Epoch 92/100\n",
      "134/134 [==============================] - 0s - loss: 0.0708 - val_loss: 0.0528\n",
      "Epoch 93/100\n",
      "134/134 [==============================] - 0s - loss: 0.0707 - val_loss: 0.0531\n",
      "Epoch 94/100\n",
      "134/134 [==============================] - 0s - loss: 0.0706 - val_loss: 0.0529\n",
      "Epoch 95/100\n",
      "134/134 [==============================] - 0s - loss: 0.0705 - val_loss: 0.0532\n",
      "Epoch 96/100\n",
      "134/134 [==============================] - 0s - loss: 0.0705 - val_loss: 0.0534\n",
      "Epoch 97/100\n",
      "134/134 [==============================] - 0s - loss: 0.0705 - val_loss: 0.0538\n",
      "Epoch 98/100\n",
      "134/134 [==============================] - 0s - loss: 0.0704 - val_loss: 0.0541\n",
      "Epoch 99/100\n",
      "134/134 [==============================] - 0s - loss: 0.0706 - val_loss: 0.0539\n",
      "Epoch 100/100\n",
      "134/134 [==============================] - 0s - loss: 0.0705 - val_loss: 0.0536\n",
      "fit done\n"
     ]
    }
   ],
   "source": [
    "# use 4 days to predict 1 day\n",
    "PRE_DAYS = 4\n",
    "ONE_DAY_DATA_LEN = 24\n",
    "def make_data(X, pre_days=PRE_DAYS):\n",
    "    xs = []\n",
    "    ys = []\n",
    "    data_len = len(X)/ONE_DAY_DATA_LEN\n",
    "    print data_len\n",
    "    for i in range(data_len-PRE_DAYS):\n",
    "        start_idx = i*ONE_DAY_DATA_LEN\n",
    "        x = X[start_idx:start_idx+pre_days*ONE_DAY_DATA_LEN]\n",
    "        y = X[start_idx+pre_days*ONE_DAY_DATA_LEN:start_idx+(1+pre_days)*ONE_DAY_DATA_LEN]\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "x,y = make_data(data.flatten())\n",
    "print x.shape,y.shape\n",
    "\n",
    "def split_train_test(x, y, n):\n",
    "    x_train, x_test = x[0:-n], x[-n:]\n",
    "    y_train, y_test = y[0:-n], y[-n:]\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "X_train, Y_train, X_test, Y_test = split_train_test(x, y, 30)\n",
    "print X_train.shape, Y_train.shape, X_test.shape, Y_test.shape\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.regularizers import l2, activity_l2\n",
    "\n",
    "INPUT_LEN = ONE_DAY_DATA_LEN * PRE_DAYS\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Activation('tanh', input_shape=(INPUT_LEN,)))\n",
    "model.add(Dense(INPUT_LEN))\n",
    "model.add(Activation('tanh', input_shape=(INPUT_LEN,)))\n",
    "model.add(Dense(INPUT_LEN/2, W_regularizer=l2(0.01), activity_regularizer=activity_l2(0.01)))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Activation('tanh', input_shape=(INPUT_LEN/2,)))\n",
    "model.add(Dense(INPUT_LEN/4, W_regularizer=l2(0.01), activity_regularizer=activity_l2(0.01)))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Activation('sigmoid', input_shape=(INPUT_LEN/4,)))\n",
    "model.add(Dense(ONE_DAY_DATA_LEN))\n",
    "\n",
    "model.compile(loss='mse', optimizer='rmsprop')\n",
    "\n",
    "print 'compile done'\n",
    "\n",
    "model.fit(X_train, Y_train, nb_epoch=100, verbose=1, batch_size=50, validation_data=(X_test, Y_test))\n",
    "\n",
    "print 'fit done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.905555555556\n",
      "0.546666666667\n",
      "0.918055555556\n",
      "0.0327868852459\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pred = model.predict(X_test).flatten().reshape(-1,1)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "pred = scaler.fit_transform(pred).round().flatten()\n",
    "\n",
    "truth = Y_test.flatten()\n",
    "\n",
    "from sklearn import metrics\n",
    "test = [0]*len(truth)\n",
    "test[0] = 1\n",
    "\n",
    "print metrics.accuracy_score(truth,pred)\n",
    "print metrics.f1_score(truth,pred)\n",
    "print metrics.accuracy_score(truth,test)\n",
    "print metrics.f1_score(truth,test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4032\n",
      "(3936, 96) (3936, 1)\n",
      "(3636, 96) (3636, 1) (300, 96) (300, 1)\n"
     ]
    }
   ],
   "source": [
    "# use 4 days to predict 1 data\n",
    "WINDOW = 4*ONE_DAY_DATA_LEN\n",
    "def make_data(X, offset = WINDOW):\n",
    "    xs = []\n",
    "    ys = []\n",
    "    data_len = len(X)\n",
    "    print data_len\n",
    "    for i in range(data_len-offset):\n",
    "        start_idx = i\n",
    "        x = X[start_idx:start_idx+offset]\n",
    "        y = X[start_idx+offset:start_idx+1+offset]\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "x,y = make_data(data.flatten())\n",
    "print x.shape,y.shape\n",
    "\n",
    "def split_train_test(x, y, n):\n",
    "    x_train, x_test = x[0:-n], x[-n:]\n",
    "    y_train, y_test = y[0:-n], y[-n:]\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "X_train, Y_train, X_test, Y_test = split_train_test(x, y, 300)\n",
    "print X_train.shape, Y_train.shape, X_test.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/label.py:108: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "0.956666666667\n",
      "0.628571428571\n",
      "train\n",
      "0.934543454345\n",
      "0.536964980545\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fae0e2e9e90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier(max_depth=3,n_estimators=100,silent=False,reg_alpha=1)\n",
    "xgb.fit(X_train,Y_train)\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "pred = xgb.predict(X_test)\n",
    "truth = Y_test\n",
    "\n",
    "print 'test'\n",
    "print metrics.accuracy_score(truth,pred)\n",
    "print metrics.f1_score(truth,pred)\n",
    "\n",
    "pred = xgb.predict(X_train)\n",
    "truth = Y_train\n",
    "\n",
    "print 'train'\n",
    "print metrics.accuracy_score(truth,pred)\n",
    "print metrics.f1_score(truth,pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
